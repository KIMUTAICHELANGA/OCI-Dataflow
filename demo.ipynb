{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo to using pyspark in OCI by use of DATA FLOW STUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def prepare_command(command: dict) -> str:\n",
    "    \"\"\"Converts dictionary command to the string formatted commands.\"\"\"\n",
    "    return f\"'{json.dumps(command)}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate with ADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "\n",
    "ads.set_auth(\"resource_principal\")  # Supported values: resource_principal, api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "compartment_id = os.environ.get(\"NB_SESSION_COMPARTMENT_OCID\")\n",
    "logs_bucket_uri = \"oci://<bucket_name>@<namespace>/<prefix>\"\n",
    "metastore_id = \"<metastore_id>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataflow spark magic allows for interaction with dataflow spark clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dataflow.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = prepare_command(\n",
    "    {\n",
    "        \"compartmentId\": compartment_id,\n",
    "        \"displayName\": \"TestDataFLowSessionFlexShapes\",\n",
    "        \"language\": \"PYTHON\",\n",
    "        \"sparkVersion\": \"3.2.1\",\n",
    "        \"numExecutors\": 1,\n",
    "        \"driverShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"executorShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"driverShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"executorShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"type\": \"SESSION\",\n",
    "        \"logsBucketUri\": logs_bucket_uri,\n",
    "        \"configuration\": {\n",
    "            \"fs.oci.client.hostname\": \"https://objectstorage.us-ashburn-1.oraclecloud.com\"\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "%create_session -l python -c $command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoscaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = prepare_command(\n",
    "    {\n",
    "        \"compartmentId\": compartment_id,\n",
    "        \"displayName\": \"TestDataFLowSessionDynamicAllocation\",\n",
    "        \"language\": \"PYTHON\",\n",
    "        \"sparkVersion\": \"3.2.1\",\n",
    "        \"numExecutors\": 2,\n",
    "        \"driverShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"executorShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"driverShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"executorShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"configuration\": {\n",
    "            \"fs.oci.client.hostname\": \"https://objectstorage.us-ashburn-1.oraclecloud.com\",\n",
    "            \"spark.dynamicAllocation.enabled\": \"true\",\n",
    "            \"spark.dynamicAllocation.shuffleTracking.enabled\": \"true\",\n",
    "            \"spark.dynamicAllocation.minExecutors\": \"1\",\n",
    "            \"spark.dynamicAllocation.maxExecutors\": \"4\",\n",
    "            \"spark.dynamicAllocation.executorIdleTimeout\": \"60\",\n",
    "            \"spark.dynamicAllocation.schedulerBacklogTimeout\": \"60\",\n",
    "            \"spark.dataflow.dynamicAllocation.quotaPolicy\": \"min\",\n",
    "        },\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = prepare_command(\n",
    "    {\n",
    "        \"driverShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"executorShape\": \"VM.Standard.E4.Flex\",\n",
    "        \"driverShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"executorShapeConfig\": {\"ocpus\": 2, \"memoryInGBs\": 32},\n",
    "        \"numExecutors\": 2,\n",
    "        \"configuration\": {\n",
    "            \"fs.oci.client.hostname\": \"https://objectstorage.us-ashburn-1.oraclecloud.com\"\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = prepare_command(\n",
    "    {\n",
    "        \"compartmentId\": \"<compartment_id>\",\n",
    "        \"displayName\": \"<display_name>\",\n",
    "        \"applicationId\": \"<application_id>\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "df_nyc_tlc = spark.read.parquet(\"oci://hosted-ds-datasets@bigdatadatasciencelarge/nyc_tlc/201[1,2,3,4,5,6,7,8]/**/data.parquet\", header=False, inferSchema=True)\n",
    "df_nyc_tlc.show()\n",
    "\n",
    "df_nyc_tlc.createOrReplaceTempView(\"nyc_tlc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -c sql -o df_nyc_tlc\n",
    "SELECT vendor_id, passenger_count, trip_distance, payment_type FROM nyc_tlc LIMIT 1000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_nyc_tlc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%stop_session"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
